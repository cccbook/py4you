# regression

來源 -- https://pytorch.org/tutorials/beginner/pytorch_with_examples.html

參考

1. https://medium.com/@Aj.Cheng/linear-regression-by-gradient-decent-bb198724eb2c
2. [Demystifying Gradient Descent and Backpropagation via Logistic Regression based Image…](https://www.freecodecamp.org/news/demystifying-gradient-descent-and-backpropagation-via-logistic-regression-based-image-classification-9b5526c2ed46/) (讚)

理論: $y = a0+a1x+a2x^2$ 的 MSE 之梯度公式，若將 dy/dai dMSE/dy 拆解，得到

dy/dai = x^i

dMSE/dy = 2 y


```
PS D:\pmedia\陳鍾誠\課程\人工智慧\07-neural\05-regression> python .\numpyRegression1.py
99 483.34270147827164
199 322.9196213614769
299 215.88160082984604
399 144.41539874989041
499 96.6719960920024
599 64.75748598329257
799 29.122369448397006
899 19.55240472766637
999 13.137953570241592
1099 8.835318852348808
1199 5.946979008426954
1299 4.006477668292744
1399 2.7016764480695232
1499 1.8235596974630215
1599 1.23206591286343
1699 0.8332703353698955
1799 0.5641388375102092
1899 0.3823345467106762
1999 0.25939830006263986
Result: y = 0.010602556941883185 + 1.012260016407776 x + 1.9981708825002162 x^2 + 2.998256119427156 x^3
PS D:\pmedia\陳鍾誠\課程\人工智慧\07-neural\05-regression> python .\torchRegression1.py
99 1189.3575439453125
199 792.89697265625
299 528.855224609375
399 352.9278564453125
499 235.65402221679688
599 157.439453125
799 70.40330505371094
899 47.12576675415039
999 31.566631317138672
1099 21.159770965576172
1199 14.194660186767578
1299 9.529600143432617
1399 6.402968406677246
1499 4.305809020996094
1599 2.898063898086548
1699 1.9523093700408936
1799 1.3164349794387817
1899 0.8885128498077393
1999 0.6002985835075378
Result: y = -0.014756614342331886 + 1.0195856094360352 x + 2.0025458335876465 x^2 + 2.9972140789031982 x^3
PS D:\pmedia\陳鍾誠\課程\人工智慧\07-neural\05-regression> python .\torchRegression2.py
99 2581.47216796875
199 1803.509521484375
299 1260.8746337890625
399 882.0884399414062
499 617.4851684570312
599 432.51708984375
699 303.130615234375
799 212.56629943847656
899 149.13699340820312
999 104.68695068359375
1099 73.5196762084961
1199 51.654685974121094
1299 36.30772399902344
1399 25.530696868896484
1499 17.959369659423828
1599 12.637990951538086
1699 8.896261215209961
1799 6.264388084411621
1899 4.412477493286133
1999 3.108927011489868
Result: y = 0.057150326669216156 + 1.0135310888290405 x + 1.9901405572891235 x^2 + 2.998075485229492 x^3
```